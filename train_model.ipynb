{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0mm\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 setuptools-80.9.0 sympy-1.14.0 torch-2.7.1 triton-3.3.1 typing-extensions-4.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting open3d\n",
      "  Using cached open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting numpy>=1.18.0 (from open3d)\n",
      "  Downloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m701.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting dash>=2.6.0 (from open3d)\n",
      "  Downloading dash-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting werkzeug>=3.0.0 (from open3d)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting flask>=3.0.0 (from open3d)\n",
      "  Using cached flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting nbformat>=5.7.0 (from open3d)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting configargparse (from open3d)\n",
      "  Using cached configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting ipywidgets>=8.0.4 (from open3d)\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting addict (from open3d)\n",
      "  Using cached addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting pillow>=9.3.0 (from open3d)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting matplotlib>=3 (from open3d)\n",
      "  Using cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pandas>=1.0 (from open3d)\n",
      "  Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m689.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.4.1 (from open3d)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting scikit-learn>=0.21 (from open3d)\n",
      "  Downloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting tqdm (from open3d)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyquaternion (from open3d)\n",
      "  Using cached pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting plotly>=5.0.0 (from dash>=2.6.0->open3d)\n",
      "  Downloading plotly-6.2.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting importlib-metadata (from dash>=2.6.0->open3d)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./venv/lib/python3.12/site-packages (from dash>=2.6.0->open3d) (4.14.0)\n",
      "Collecting requests (from dash>=2.6.0->open3d)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting retrying (from dash>=2.6.0->open3d)\n",
      "  Downloading retrying-1.4.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.12/site-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from dash>=2.6.0->open3d) (80.9.0)\n",
      "Collecting blinker>=1.9.0 (from flask>=3.0.0->open3d)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting click>=8.1.3 (from flask>=3.0.0->open3d)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from flask>=3.0.0->open3d)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in ./venv/lib/python3.12/site-packages (from flask>=3.0.0->open3d) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./venv/lib/python3.12/site-packages (from flask>=3.0.0->open3d) (3.0.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./venv/lib/python3.12/site-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./venv/lib/python3.12/site-packages (from ipywidgets>=8.0.4->open3d) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./venv/lib/python3.12/site-packages (from ipywidgets>=8.0.4->open3d) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.0.4->open3d)\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets>=8.0.4->open3d)\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3->open3d)\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3->open3d)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3->open3d)\n",
      "  Downloading fonttools-4.58.5-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m316.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=3->open3d)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib>=3->open3d) (25.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3->open3d)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib>=3->open3d) (2.9.0.post0)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7.0->open3d)\n",
      "  Using cached fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat>=5.7.0->open3d)\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./venv/lib/python3.12/site-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.0->open3d)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.0->open3d)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn>=0.21->open3d)\n",
      "  Downloading scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m165.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn>=0.21->open3d)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.21->open3d)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.6.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat>=5.7.0->open3d)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat>=5.7.0->open3d)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat>=5.7.0->open3d)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat>=5.7.0->open3d)\n",
      "  Downloading rpds_py-0.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
      "Collecting narwhals>=1.15.1 (from plotly>=5.0.0->dash>=2.6.0->open3d)\n",
      "  Downloading narwhals-1.45.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.17.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata->dash>=2.6.0->open3d)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->dash>=2.6.0->open3d)\n",
      "  Using cached charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->dash>=2.6.0->open3d)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->dash>=2.6.0->open3d)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->dash>=2.6.0->open3d)\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.3)\n",
      "Using cached open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl (447.7 MB)\n",
      "Downloading dash-3.1.1-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m208.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m132.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Using cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m191.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m174.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m182.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "Downloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m188.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m245.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Using cached configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
      "Using cached pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Downloading fonttools-4.58.5-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m223.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m156.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "Downloading plotly-6.2.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m139.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.1/35.1 MB\u001b[0m \u001b[31m134.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m124.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading retrying-1.4.0-py3-none-any.whl (11 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.7/157.7 kB\u001b[0m \u001b[31m131.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading narwhals-1.45.0-py3-none-any.whl (371 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.6/371.6 kB\u001b[0m \u001b[31m128.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.1/386.1 kB\u001b[0m \u001b[31m111.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m105.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: pytz, fastjsonschema, addict, zipp, widgetsnbextension, werkzeug, urllib3, tzdata, tqdm, threadpoolctl, rpds-py, retrying, pyyaml, pyparsing, pillow, numpy, narwhals, kiwisolver, jupyterlab_widgets, joblib, itsdangerous, idna, fonttools, cycler, configargparse, click, charset_normalizer, certifi, blinker, attrs, scipy, requests, referencing, pyquaternion, plotly, pandas, importlib-metadata, flask, contourpy, scikit-learn, matplotlib, jsonschema-specifications, ipywidgets, dash, jsonschema, nbformat, open3d\n",
      "Successfully installed addict-2.4.0 attrs-25.3.0 blinker-1.9.0 certifi-2025.6.15 charset_normalizer-3.4.2 click-8.2.1 configargparse-1.7.1 contourpy-1.3.2 cycler-0.12.1 dash-3.1.1 fastjsonschema-2.21.1 flask-3.1.1 fonttools-4.58.5 idna-3.10 importlib-metadata-8.7.0 ipywidgets-8.1.7 itsdangerous-2.2.0 joblib-1.5.1 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 jupyterlab_widgets-3.0.15 kiwisolver-1.4.8 matplotlib-3.10.3 narwhals-1.45.0 nbformat-5.10.4 numpy-2.3.1 open3d-0.19.0 pandas-2.3.0 pillow-11.3.0 plotly-6.2.0 pyparsing-3.2.3 pyquaternion-0.9.9 pytz-2025.2 pyyaml-6.0.2 referencing-0.36.2 requests-2.32.4 retrying-1.4.0 rpds-py-0.26.0 scikit-learn-1.7.0 scipy-1.16.0 threadpoolctl-3.6.0 tqdm-4.67.1 tzdata-2025.2 urllib3-2.5.0 werkzeug-3.1.3 widgetsnbextension-4.0.14 zipp-3.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Instalaciones\n",
    "\n",
    "%pip install torch\n",
    "%pip install open3d\n",
    "%pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "## Dependencias\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from model import PointNetClassifier, PointNetLoss, PointNetKAN\n",
    "from modelnet10 import ModelNetClass, ModelNet, DatasetType\n",
    "from utils.csv import save_loss_dict\n",
    "from utils.transformation import Normalization, Rotation, Translation, Reflection, Scale\n",
    "from trainer import PointNetTrainer\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {DEVICE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parámetros del dataset\n",
    "classes = [label for label in ModelNetClass]\n",
    "batch_size = 32\n",
    "dim = 3\n",
    "num_points = 1024\n",
    "num_classes = len(classes)\n",
    "\n",
    "# hiperparámetros\n",
    "num_global_feats = 1024     # número de features globales calculadas\n",
    "learning_rate = 0.001\n",
    "reg_weight = 0.001\n",
    "gamma = 2                   # Recomendado por el paper de focal loss\n",
    "\n",
    "# dataset\n",
    "transformations = [Normalization(), Rotation(), Translation(normalize=True), Reflection(), Scale()]\n",
    "\n",
    "train_data = ModelNet(classes, DatasetType.TRAIN, transformations)\n",
    "validation_data = ModelNet(classes, DatasetType.VALIDATION, transformations)\n",
    "test_data = ModelNet(classes, DatasetType.TEST, preserve_original=False)\n",
    "\n",
    "train_loader= DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "# TODO: Más adelante usar alpha para clases imbalanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<<<<<<< transformation\n",
    "classifier = PointnetClassifier(dim, num_points, num_global_feats, num_classes).to(DEVICE)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "if DEVICE == \"cuda\":\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, step_size_up=2000, cycle_momentum=False)\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "base_trainer = PointNetTrainer(\n",
    "    name=\"pointnet_base\",\n",
    "    model=classifier,\n",
    "    optimizer=optimizer,\n",
    "#=======\n",
    "base_classifier = PointNetClassifier(dim, num_points, num_global_feats, num_classes).to(DEVICE)\n",
    "kan_classifier = PointNetKAN(dim, num_classes, scaling = 3.0).to(DEVICE) \n",
    "\n",
    "base_trainer = PointNetTrainer(\n",
    "    name=\"pointnet_base\",\n",
    "    model=base_classifier,\n",
    "    optimizer=optim.Adam(base_classifier.parameters(), lr=learning_rate),\n",
    "#>>>>>>> main\n",
    "    scheduler=scheduler,\n",
    "    criterion=PointNetLoss(alpha=None, gamma=gamma, reg_weight=reg_weight, size_average=True).to(DEVICE),\n",
    "    device=DEVICE,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    checkpoint_dir=os.path.join(os.getcwd(), \"checkpoint\"),\n",
    "    checkpoint_freq=25\n",
    ")\n",
    "\n",
    "# Para este reg_weight = 0, al menos hasta que se decida si utilizar T-net o no.\n",
    "kan_trainer = PointNetTrainer(\n",
    "    name=\"pointnet_kan\",\n",
    "    model=kan_classifier,\n",
    "    optimizer=optim.Adam(kan_classifier.parameters(), lr=learning_rate),\n",
    "    scheduler=scheduler,\n",
    "    criterion=PointNetLoss(alpha=None, gamma=gamma, reg_weight=0, size_average=True).to(DEVICE),\n",
    "    device=DEVICE,\n",
    "    train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True),\n",
    "    val_loader=DataLoader(validation_data, batch_size=batch_size, shuffle=False),\n",
    "    checkpoint_dir=os.path.join(os.getcwd(), \"checkpoint\"),\n",
    "    checkpoint_freq=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loss_dict, best_epoch, best_loss, best_acc = \u001b[43mbase_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m save_loss_dict(loss_dict)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest model @ epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, acc = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/modelNet10classifier/trainer.py:118\u001b[39m, in \u001b[36mPointNetTrainer.fit\u001b[39m\u001b[34m(self, epochs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m         train_loss, train_acc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m         val_loss, val_acc = \u001b[38;5;28mself\u001b[39m._validate_epoch()\n\u001b[32m    121\u001b[39m         \u001b[38;5;28mself\u001b[39m.loss_dict[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m].append(train_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/modelNet10classifier/trainer.py:56\u001b[39m, in \u001b[36mPointNetTrainer._train_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     53\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.criterion(out, labels, A, is_train=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Hacemos backprop, optimizamos\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.step()\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Si se está haciendo uso de scheduler para LR, lo utilizamos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/modelNet10classifier/venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/modelNet10classifier/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:346\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    337\u001b[39m inputs = (\n\u001b[32m    338\u001b[39m     (inputs,)\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch.Tensor, graph.GradientEdge))\n\u001b[32m   (...)\u001b[39m\u001b[32m    342\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    343\u001b[39m )\n\u001b[32m    345\u001b[39m grad_tensors_ = _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m grad_tensors_ = \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/modelNet10classifier/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:221\u001b[39m, in \u001b[36m_make_grads\u001b[39m\u001b[34m(outputs, grads, is_grads_batched)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    219\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, torch.Tensor)\n\u001b[32m    220\u001b[39m         new_grads.append(\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m             \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m         )\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    224\u001b[39m     new_grads.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# loss_dict, best_epoch, best_loss, best_acc = base_trainer.fit(epochs=500)\n",
    "loss_dict, best_epoch, best_loss, best_acc = kan_trainer.fit(epochs=500)\n",
    "save_loss_dict(loss_dict)\n",
    "print(f\"Best model @ epoch {best_epoch}: loss = {best_loss:.4f}, acc = {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    classifier = classifier.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    for pcds, labels in test_loader:\n",
    "        pcds = pcds.to(DEVICE)\n",
    "        labels = labels.squeeze().to(DEVICE)\n",
    "        \n",
    "        # Hacer predicciones\n",
    "        out, _, _ = classifier(pcds)\n",
    "    \n",
    "        # Calculamos las elecciones\n",
    "        pred_choice = torch.softmax(out, dim=1).argmax(dim=1)\n",
    "        \n",
    "        # Elecciones correctas, acumuladas\n",
    "        correct += pred_choice.eq(labels.data).cpu().sum().item()\n",
    "\n",
    "    test_acc = correct / float(len(test_data))\n",
    "    print(\"Test Acc:\\t\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_it(path):\n",
    "    classifier = PointnetClassifier(dim, num_points, num_global_feats, num_classes).to(DEVICE)\n",
    "    classifier.load_state_dict(torch.load(path))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        classifier = classifier.eval()\n",
    "        correct = 0\n",
    "        \n",
    "        for pcds, labels in test_loader:\n",
    "            pcds = pcds.to(DEVICE)\n",
    "            labels = labels.squeeze().to(DEVICE)\n",
    "            \n",
    "            # Hacer predicciones\n",
    "            out, _, _ = classifier(pcds)\n",
    "        \n",
    "            # Calculamos las elecciones\n",
    "            pred_choice = torch.softmax(out, dim=1).argmax(dim=1)\n",
    "            \n",
    "            # Elecciones correctas, acumuladas\n",
    "            correct += pred_choice.eq(labels.data).cpu().sum().item()\n",
    "\n",
    "        test_acc = correct / float(len(test_data))\n",
    "        print(f\"{path}\\t\\t\", test_acc)\n",
    "\n",
    "# Tests\n",
    "for i in range(25, 500 + 1, 25):\n",
    "    path = os.path.join(CHECKPOINT_DIR, f\"model_epoch_{str(i).zfill(4)}.pth\")\n",
    "    test_it(path)\n",
    "path = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n",
    "test_it(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
