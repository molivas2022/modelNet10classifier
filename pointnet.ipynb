{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch) (80.8.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch)\n",
      "  Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (865.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.0/865.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.5.0 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 triton-3.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Instalaciones\n",
    "\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencias\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## T-net\n",
    "\"\"\"\n",
    "T-net es una 'mini-red' que aprende una matriz de transformación de tamaño\n",
    "dimxdim que transforma la entrada a una representación 'canónica', la cuál\n",
    "es invariante a transformaciones rigidas (rotación, translación, reflexión).\n",
    "\"\"\"\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "    def __init__(self, dim, num_points):\n",
    "        super(Tnet, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "\n",
    "        # Función de activación\n",
    "        self.act = F.relu\n",
    "\n",
    "        # Conv1d es una implementación sencilla de una 'MLP compartida'\n",
    "        self.shared_mlp1 = nn.Conv1d(dim, 64, kernel_size=1)\n",
    "        self.shared_mlp2 = nn.Conv1d(64, 128, kernel_size=1)\n",
    "        self.shared_mlp3 = nn.Conv1d(128, 1024, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=num_points)\n",
    "\n",
    "        # MLPs no compartidas\n",
    "        self.linear1 = nn.Linear(1024, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.linear3 = nn.Linear(256, dim**2)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "\n",
    "        # Paso a través de las MLPs compartidas\n",
    "        x = self.bn1(self.act(self.shared_mlp1(x)))\n",
    "        x = self.bn2(self.act(self.shared_mlp2(x)))\n",
    "        x = self.bn3(self.act(self.shared_mlp3(x)))\n",
    "\n",
    "        # Max pool\n",
    "        x = self.max_pool(x).view(bs, -1)\n",
    "        \n",
    "        # Paso a través de las MLPs no compartidas\n",
    "        x = self.bn4(self.act(self.linear1(x)))\n",
    "        x = self.bn5(self.act(self.linear2(x)))\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        # Reshape de 'T-Net(x)' a una matriz\n",
    "        x = x.view(-1, self.dim, self.dim)\n",
    "        # Le sumamos la matriz identidad para mayor estabilidad\n",
    "        iden = torch.eye(self.dim, requires_grad=True).repeat(bs, 1, 1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x += iden\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Point-net classifier\n",
    "\n",
    "class PointnetClassifier(nn.Module):\n",
    "    def __init__(self, dim, num_points, num_global_feats, num_classes):\n",
    "        super(PointnetClassifier, self).__init__()\n",
    "\n",
    "        # Función de activación\n",
    "        self.act = F.relu\n",
    "\n",
    "        # T-Net en los puntos de la entrada\n",
    "        self.input_transform = Tnet(dim, num_points)\n",
    "\n",
    "        # Primera MLP compartida, transforma los puntos de la entrada en features\n",
    "        self.shared_mlp1 = nn.Conv1d(3, 64, kernel_size=1)\n",
    "        self.shared_mlp2 = nn.Conv1d(64, 64, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "\n",
    "        # T-Net en las features\n",
    "        self.feature_transform = Tnet(64, num_points)\n",
    "\n",
    "        # Segunda MLP compartida, determina las features globales\n",
    "        self.shared_mlp3 = nn.Conv1d(64, 64, kernel_size=1)\n",
    "        self.shared_mlp4 = nn.Conv1d(64, 128, kernel_size=1)\n",
    "        self.shared_mlp5 = nn.Conv1d(128, num_global_feats, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.bn5 = nn.BatchNorm1d(num_global_feats)\n",
    "        # Max pool para extraer las features globales\n",
    "        # Devolver los indices nos permite ver los indices críticos que determinan las features globales\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=num_points, return_indices=True)\n",
    "\n",
    "        # MLP para clasificación\n",
    "        self.linear1 = nn.Linear(num_global_feats, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.bn_linear1 = nn.BatchNorm1d(512)\n",
    "        self.bn_linear2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "        # Output layer\n",
    "        self.linear3 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Tamaño del batch, es decir cuantos ejemplos hay en el batch\n",
    "        bs = x.shape[0]\n",
    "\n",
    "        # Transformación del input\n",
    "        input_matrix = self.input_transform(x)\n",
    "        # x = torch.bmm(x.tranpose(2, 1), input_matrix).tranpose(2, 1)\n",
    "        x = torch.transpose(torch.bmm(torch.transpose(x, 2, 1), input_matrix), 2, 1)\n",
    "\n",
    "        # Paso a través de las primeras MLPs compartidas\n",
    "        x = self.bn1(self.act(self.shared_mlp1(x)))\n",
    "        x = self.bn2(self.act(self.shared_mlp2(x)))\n",
    "\n",
    "        # Transformación de features\n",
    "        feature_matrix = self.feature_transform(x)\n",
    "        # x = torch.bmm(x.tranpose(2, 1), feature_matrix).tranpose(2, 1)\n",
    "        x = torch.transpose(torch.bmm(torch.transpose(x, 2, 1), feature_matrix), 2, 1)\n",
    "\n",
    "        # Paso a través de las segundas MLPs compartidas\n",
    "        x = self.bn3(self.act(self.shared_mlp3(x)))\n",
    "        x = self.bn4(self.act(self.shared_mlp4(x)))\n",
    "        x = self.bn5(self.act(self.shared_mlp5(x)))\n",
    "\n",
    "        global_features, critical_indexes = self.max_pool(x)\n",
    "        global_features = global_features.view(bs, -1)\n",
    "        critical_indexes = critical_indexes.view(bs, -1)\n",
    "\n",
    "        # Clasificación\n",
    "        x = self.bn_linear1(self.act(self.linear1(global_features)))\n",
    "        x = self.bn_linear2(self.act(self.linear2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        # Devolver logits\n",
    "        return x, critical_indexes, feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class output shape: torch.Size([32, 2])\n",
      "Class output: tensor([[ 6.0447e-01, -6.1188e-01],\n",
      "        [ 6.9314e-02,  7.3064e-01],\n",
      "        [ 2.8404e-01,  4.3951e-01],\n",
      "        [ 4.2944e-01, -3.8633e-01],\n",
      "        [-1.0889e-01,  2.9398e-01],\n",
      "        [ 5.9915e-01,  1.2308e-03],\n",
      "        [ 4.9978e-01,  6.7860e-01],\n",
      "        [ 6.9066e-01,  3.9589e-01],\n",
      "        [ 1.7057e-01,  4.5106e-01],\n",
      "        [-2.3058e-01,  2.8857e-01],\n",
      "        [ 1.1676e+00,  2.4708e+00],\n",
      "        [-7.0644e-01,  4.6825e-02],\n",
      "        [-5.7438e-01, -9.9266e-01],\n",
      "        [-9.6524e-01,  3.2507e-01],\n",
      "        [-5.5060e-01, -1.2496e-03],\n",
      "        [ 4.7521e-01, -4.5222e-01],\n",
      "        [-3.6642e-01, -7.8267e-01],\n",
      "        [ 2.2702e-01, -7.0550e-01],\n",
      "        [ 4.7587e-01, -1.4030e-01],\n",
      "        [-6.2072e-01,  7.1639e-01],\n",
      "        [ 1.0209e-01,  2.0904e+00],\n",
      "        [ 1.0551e-01, -8.1594e-02],\n",
      "        [ 2.4185e-01,  3.7723e-01],\n",
      "        [-1.0678e-02, -1.4720e+00],\n",
      "        [-6.1999e-01, -5.5066e-01],\n",
      "        [-1.1785e+00,  1.3708e+00],\n",
      "        [ 2.8073e-01,  1.3444e-01],\n",
      "        [-3.8522e-01, -5.0707e-01],\n",
      "        [-6.3517e-01,  5.3190e-01],\n",
      "        [-8.0856e-02, -9.2739e-02],\n",
      "        [ 7.7298e-01, -5.7507e-01],\n",
      "        [ 4.0905e-01,  4.2234e-01]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "\n",
    "# parametros del dataset\n",
    "batch_size = 32             # número de point clouds\n",
    "dim = 3                     # número de dimensiones por cada punto\n",
    "num_points = 1024           # número de puntos por point cloud\n",
    "num_classes = 2             # número de clases de clasificación\n",
    "\n",
    "# hiperparametros\n",
    "num_global_feats = 1024     # número de features globales calculadas\n",
    "\n",
    "test_data = torch.rand(batch_size, dim, num_points)\n",
    "\n",
    "classifier = PointnetClassifier(dim, num_points, num_global_feats, num_classes)\n",
    "out, _, _ = classifier(test_data)\n",
    "print(f'Class output shape: {out.shape}')\n",
    "print(f'Class output: {out}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
